<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="theme-color" content="#d9b6f1">
    <title>AI Sign Language Detector</title>

    <link rel="manifest" href="manifest.json">

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>

    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; font-family: 'Nunito', sans-serif; -webkit-tap-highlight-color: transparent; }
        body { background: linear-gradient(160deg, #e3b6f5 0%, #879bde 45%, #4c9db0 100%); min-height: 100vh; display: flex; justify-content: center; align-items: center; color: white; overflow: hidden; }
        
        #app-container { width: 100%; max-width: 400px; height: 100vh; max-height: 850px; position: relative; display: flex; flex-direction: column; overflow: hidden; }
        .bg-pattern { position: absolute; top: 0; left: 0; right: 0; bottom: 0; background-image: radial-gradient(circle at center, rgba(255,255,255,0.1) 1px, transparent 1px); background-size: 30px 30px; opacity: 0.3; z-index: 0; pointer-events: none; }

        .screen { position: absolute; top: 0; left: 0; width: 100%; height: 100%; display: flex; flex-direction: column; align-items: center; padding: 40px 20px; z-index: 1; transition: opacity 0.3s ease, transform 0.3s ease; opacity: 0; pointer-events: none; transform: translateX(20px); }
        .screen.active { opacity: 1; pointer-events: auto; transform: translateX(0); }

        #welcome-screen { justify-content: center; text-align: center; }
        .logo-box { width: 90px; height: 90px; background-color: #f0fdf4; border-radius: 20px; display: flex; justify-content: center; align-items: center; margin-bottom: 25px; box-shadow: 0 4px 15px rgba(0,0,0,0.1); font-size: 45px;}
        .welcome-title { font-size: 26px; font-weight: 800; line-height: 1.2; margin-bottom: 30px; text-shadow: 1px 1px 3px rgba(0,0,0,0.2); }
        .welcome-subtitle { font-size: 14px; font-weight: 500; line-height: 1.5; margin-bottom: 80px; color: rgba(255, 255, 255, 0.9); }
        
        .primary-btn { background-color: #1e1136; color: white; border: none; padding: 16px 0; width: 85%; border-radius: 30px; font-size: 14px; font-weight: 800; letter-spacing: 1px; cursor: pointer; box-shadow: 0 5px 15px rgba(0,0,0,0.2); transition: transform 0.1s; }
        .primary-btn:active { transform: scale(0.97); }

        #detector-screen { justify-content: flex-start; padding-top: 50px; }
        .header-title { font-size: 22px; font-weight: 700; text-align: center; margin-bottom: 30px; color: rgba(255, 255, 255, 0.85); line-height: 1.2; }
        .detector-card { background: rgba(255, 255, 255, 0.15); backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); border: 2px solid rgba(255, 255, 255, 0.5); border-radius: 20px; width: 100%; padding: 25px 20px; display: flex; flex-direction: column; align-items: center; box-shadow: 0 8px 32px rgba(0,0,0,0.1); }

        .camera-feed { width: 100%; height: 200px; background-color: rgba(0, 0, 0, 0.5); border: 3px solid white; border-radius: 15px; display: flex; flex-direction: column; justify-content: center; align-items: center; margin-bottom: 25px; position: relative; overflow: hidden; }
        .input_video { display: none; }
        .output_canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); }
        .loading-text { position: absolute; z-index: 10; font-size: 14px; font-weight: bold; text-align: center; color: white;}

        .output-label { font-size: 13px; align-self: flex-start; margin-bottom: 15px; color: rgba(255, 255, 255, 0.9); }
        .output-container { width: 100%; background-color: white; border-radius: 30px; display: flex; justify-content: space-between; align-items: center; padding: 8px 8px 8px 20px; margin-bottom: 30px; }
        .output-text { color: #333; font-size: 14px; font-weight: 700; }
        .clear-btn { background: linear-gradient(135deg, #62c370, #3fb050); border: none; width: 40px; height: 40px; border-radius: 50%; display: flex; flex-direction: column; justify-content: center; align-items: center; cursor: pointer; color: white; font-size: 16px; box-shadow: 0 2px 5px rgba(0,0,0,0.2); }
        .back-btn { position: absolute; bottom: 30px; left: 20px; width: 40px; height: 40px; background-color: white; border: none; border-radius: 50%; display: flex; justify-content: center; align-items: center; color: #555; font-size: 18px; cursor: pointer; box-shadow: 0 4px 10px rgba(0,0,0,0.15); z-index: 10; }
    </style>
</head>
<body>

    <div id="app-container">
        <div class="bg-pattern"></div>
        <div id="welcome-screen" class="screen active">
            <div class="logo-box"><span>ü§ü</span></div>
            <h1 class="welcome-title">Welcome to<br>AI Sign Language<br>Detector</h1>
            <p class="welcome-subtitle">An app that uses AI to recognize<br>and translate sign language in<br>real-time.</p>
            <button id="btn-get-started" class="primary-btn">GET STARTED</button>
        </div>

        <div id="detector-screen" class="screen">
            <h2 class="header-title">AI Sign Language<br>Detector</h2>
            <div class="detector-card">
                <div class="camera-feed">
                    <span class="loading-text" id="loading-msg">Waiting for Camera...<br>(Please allow access)</span>
                    <video class="input_video"></video>
                    <canvas class="output_canvas" width="480" height="360"></canvas>
                </div>

                <p class="output-label">Output from the sign language<br>you entered:</p>

                <div class="output-container">
                    <span class="output-text" id="translation-output">Waiting for signs...</span>
                    <button class="clear-btn" id="btn-clear"><span>‚úñ</span></button>
                </div>

                <button class="primary-btn" id="btn-start-detection" style="width: 100%;">START AI DETECTION</button>
            </div>
            <button id="btn-back" class="back-btn">‚ùÆ</button>
        </div>
    </div>

    <script>
        const getStartedBtn = document.getElementById('btn-get-started');
        const backBtn = document.getElementById('btn-back');
        const welcomeScreen = document.getElementById('welcome-screen');
        const detectorScreen = document.getElementById('detector-screen');

        getStartedBtn.addEventListener('click', () => {
            welcomeScreen.classList.remove('active');
            detectorScreen.classList.add('active');
        });

        backBtn.addEventListener('click', () => {
            detectorScreen.classList.remove('active');
            welcomeScreen.classList.add('active');
        });

        const videoElement = document.querySelector('.input_video');
        const canvasElement = document.querySelector('.output_canvas');
        const canvasCtx = canvasElement.getContext('2d');
        const loadingMsg = document.getElementById('loading-msg');
        const translationOutput = document.getElementById('translation-output');
        const btnStart = document.getElementById('btn-start-detection');
        let isDetecting = false;

        let signModel;
        const class_list = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'];

        async function loadAI() {
            try {
                signModel = await tf.loadLayersModel('./model.json');
                console.log("AI Model Loaded Successfully!");
            } catch (error) {
                console.error("Error loading model:", error);
            }
        }
        loadAI();

        let lastSendTime = 0;

        async function onResults(results) {
            loadingMsg.style.display = "none";

            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0 && isDetecting) {
                const hand = results.multiHandLandmarks[0];
                
                drawConnectors(canvasCtx, hand, HAND_CONNECTIONS, {color: '#00FF00', lineWidth: 3});
                drawLandmarks(canvasCtx, hand, {color: '#FF0000', lineWidth: 1});
                
                const now = Date.now();
                if (now - lastSendTime > 300) {
                    lastSendTime = now;
                    
                    let coordinate_xy = [];
                    
                    // FIXED: We perfectly mirror the camera, just like PictoBlox does by default
                    for (let i = 0; i < 21; i++) {
                        let mirroredX = 1.0 - hand[i].x; 
                        
                        let x = Math.round(mirroredX * 480);
                        let y = Math.round(hand[i].y * 360);
                        coordinate_xy.push(x);
                        coordinate_xy.push(y);
                    }

                    if (signModel) {
                        const inputTensor = tf.tensor2d([coordinate_xy]);
                        const prediction = signModel.predict(inputTensor);
                        const predictArray = await prediction.data();
                        
                        let maxIndex = 0;
                        let maxValue = predictArray[0];
                        for (let i = 1; i < predictArray.length; i++) {
                            if (predictArray[i] > maxValue) {
                                maxValue = predictArray[i];
                                maxIndex = i;
                            }
                        }
                        
                        translationOutput.innerText = "Number: " + class_list[maxIndex];
                        translationOutput.style.color = "#3fb050";
                        translationOutput.style.fontSize = "18px";
                        
                        inputTensor.dispose();
                    }
                }
            } else if (isDetecting) {
                translationOutput.innerText = "No hand in frame...";
                translationOutput.style.color = "#999";
            }
            canvasCtx.restore();
        }

        const hands = new Hands({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
        }});

        hands.setOptions({
            maxNumHands: 1, 
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });
        
        hands.onResults(onResults);

        const camera = new Camera(videoElement, {
            onFrame: async () => {
                await hands.send({image: videoElement});
            },
            width: 480, // FIXED: Forces the exact 480x360 ratio you trained the AI with
            height: 360
        });
        camera.start();

        btnStart.addEventListener('click', () => {
            isDetecting = !isDetecting;
            if(isDetecting) {
                btnStart.innerText = "STOP DETECTION";
                btnStart.style.backgroundColor = "#c0392b"; 
                translationOutput.innerText = "Analyzing gestures...";
            } else {
                btnStart.innerText = "START AI DETECTION";
                btnStart.style.backgroundColor = "#1e1136";
                translationOutput.innerText = "Detection Paused.";
            }
        });

        document.getElementById('btn-clear').addEventListener('click', () => {
            translationOutput.innerText = "Sign language interpretation...";
            translationOutput.style.color = "#999";
            translationOutput.style.fontSize = "14px";
        });
    </script>

    <script>
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                navigator.serviceWorker.register('sw.js')
                    .then((reg) => console.log('Service worker registered.', reg))
                    .catch((err) => console.log('Service worker not registered.', err));
            });
        }
    </script>

</body>
</html>